name: Sync cards from Google

on:
  workflow_dispatch: {}
  schedule:
    - cron: '0 * * * *'  # every hour

permissions:
  contents: write

concurrency:
  group: cards-sync
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Ensure repo is up to date
        run: |
          set -euo pipefail
          git fetch origin main
          git checkout main
          git reset --hard origin/main

      # Optional: clear old versioned folders before writing new ones
      - name: Clean old versioned folders
        run: rm -rf public/campaigns.v-*

      - name: Build cards (canonical + versioned + index + per-slug + manifest + home + feeds pointer)
        run: node scripts/build_cards.js

      - name: Commit generated files
        id: commit
        run: |
          set -euo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A public
          if git diff --cached --quiet; then
            echo "No changes to commit"
            echo "changed=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          git commit -m "Update cards feed from Google"
          git push origin HEAD:main
          echo "changed=true" >> "$GITHUB_OUTPUT"

      - name: Purge jsDelivr caches
        if: steps.commit.outputs.changed == 'true'
        run: |
          set -euo pipefail
          purge() { for i in 1 2 3; do curl -fsS "$1" && return 0 || sleep 2; done; return 1; }

          # Pointers used by the site
          purge https://purge.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/feeds.latest.json
          purge https://purge.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/cards.latest.json

          # Legacy non-versioned files (safe to purge if you still expose them)
          purge https://purge.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/campaigns.cards.min.json
          purge https://purge.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/campaigns.index.min.json
          purge https://purge.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/campaigns.home.min.json
          purge https://purge.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/campaigns.manifest.json

          # Versioned aggregated file purge derived from cards.latest.json pointer
          VERSIONED_URL=$(node -e "console.log(require('./public/cards.latest.json').url)")
          PURGE_URL="${VERSIONED_URL/cdn.jsdelivr.net\/gh/purge.jsdelivr.net\/gh}"
          purge "$PURGE_URL"

          # Per-slug files live in a new versioned folder each build, no purge needed

      - name: Verify feeds pointer is live on CDN
        if: steps.commit.outputs.changed == 'true'
        run: |
          set -euo pipefail

          # Expected values from the file we just wrote locally
          WANT_PER=$(node -e "const j=require('./public/feeds.latest.json'); const s=(j.per_slug_base||''); console.log((s.replace(/\/+$/,'') + '/'))")
          WANT_INDEX=$(node -e "const j=require('./public/feeds.latest.json'); console.log(j.index_url||'')")
          WANT_HOME=$(node -e "const j=require('./public/feeds.latest.json'); console.log(j.home_url||'')")

          FEEDS_URL="https://cdn.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/feeds.latest.json?v=$(date +%s)"
          echo "Waiting for feeds pointer: $FEEDS_URL"

          ok=0
          for i in $(seq 1 90); do
            LIVE_JSON=$(curl -fsSL "$FEEDS_URL" || true)
            if [ -z "$LIVE_JSON" ]; then
              echo "Attempt $i: empty response"
              sleep 5
              continue
            fi

            GOT_PER=$(node -e "const j=JSON.parse(process.env.J||'{}'); const s=(j.per_slug_base||''); console.log((s.replace(/\/+$/,'') + '/'))" J="$LIVE_JSON")
            GOT_INDEX=$(node -e "const j=JSON.parse(process.env.J||'{}'); console.log(j.index_url||'')" J="$LIVE_JSON")
            GOT_HOME=$(node -e "const j=JSON.parse(process.env.J||'{}'); console.log(j.home_url||'')" J="$LIVE_JSON")

            if [ "$GOT_PER" = "$WANT_PER" ] && [ "$GOT_INDEX" = "$WANT_INDEX" ] && [ "$GOT_HOME" = "$WANT_HOME" ]; then
              echo "feeds.latest.json is live."
              ok=1
              break
            fi

            echo "Attempt $i mismatch:"
            echo "  per_slug_base:"
            echo "    want: $WANT_PER"
            echo "    live: $GOT_PER"
            echo "  index_url:"
            echo "    want: $WANT_INDEX"
            echo "    live: $GOT_INDEX"
            echo "  home_url:"
            echo "    want: $WANT_HOME"
            echo "    live: $GOT_HOME"
            sleep 5
          done

          if [ "$ok" != "1" ]; then
            echo "feeds.latest.json did not update in time"
            exit 1
          fi

      - name: Verify versioned files are live on CDN
        if: steps.commit.outputs.changed == 'true'
        run: |
          set -euo pipefail

          # Aggregated versioned file from cards.latest.json
          VERSIONED_URL=$(node -e "console.log(require('./public/cards.latest.json').url)")
          echo "Waiting for versioned aggregated: $VERSIONED_URL"
          for i in $(seq 1 90); do
            code=$(curl -s -o /dev/null -w "%{http_code}" "$VERSIONED_URL")
            [ "$code" = "200" ] && { echo "Aggregated file live."; break; }
            sleep 5
          done

          # Index and home versioned files from the feeds pointer we just verified
          INDEX_URL=$(node -e "const j=require('./public/feeds.latest.json'); console.log(j.index_url)")
          HOME_URL=$(node -e "const j=require('./public/feeds.latest.json'); console.log(j.home_url)")

          echo "Waiting for index: $INDEX_URL"
          for i in $(seq 1 90); do
            code=$(curl -s -o /dev/null -w "%{http_code}" "$INDEX_URL")
            [ "$code" = "200" ] && { echo "Index file live."; break; }
            sleep 5
          done

          echo "Waiting for home: $HOME_URL"
          for i in $(seq 1 90); do
            code=$(curl -s -o /dev/null -w "%{http_code}" "$HOME_URL")
            [ "$code" = "200" ] && { echo "Home file live."; break; }
            sleep 5
          done

      - name: Check cards.latest.json pointer (non-fatal)
        if: steps.commit.outputs.changed == 'true'
        continue-on-error: true
        run: |
          set -euo pipefail
          LATEST_URL="https://cdn.jsdelivr.net/gh/Jrosai-dev/fundlibraries-campaigns@main/public/cards.latest.json?v=$(date +%s)"
          echo "Checking cards.latest.json: $LATEST_URL"
          for i in $(seq 1 60); do
            code=$(curl -s -o latest.json -w "%{http_code}" "$LATEST_URL")
            if [ "$code" = "200" ] && grep -q '"url":' latest.json; then
              echo "cards.latest.json pointer is visible."
              exit 0
            fi
            sleep 5
          done
          echo "cards.latest.json still stale. Continuing."
